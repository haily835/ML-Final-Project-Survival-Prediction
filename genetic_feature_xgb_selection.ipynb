{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv('./data/processed_mrna_zscore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-2]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 500 features by filtering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './top_features_rf_500.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read().splitlines()\n",
    "top500 = content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search space is now in 500 top features selected by a filtering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_n = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Assuming X and y are your feature matrix and target variable\n",
    "# X is a pandas DataFrame with 1800 samples and 500 features\n",
    "# y is a pandas Series with the corresponding labels\n",
    "\n",
    "# DEAP initialization\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# Function to create an individual (binary representation of features)\n",
    "def create_individual():\n",
    "    return np.random.choice(top500, size=target_n, replace=False)\n",
    "\n",
    "def mutate(individual, indpb):\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < indpb:\n",
    "            remain = [feat for feat in top500 if feat not in individual]\n",
    "            individual[i] = np.random.choice(remain)\n",
    "    return individual,\n",
    "# DEAP Toolbox\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, create_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", mutate, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genetic algorithm settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 50\n",
    "generations = 20\n",
    "crossover_rate = 0.8\n",
    "mutation_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execuate_ga(clf):\n",
    "    # Collect fitness values for plotting\n",
    "    mean_fitness_values = []\n",
    "\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    for gen in range(generations):\n",
    "        # Evaluate the entire population\n",
    "        fitness_values = list(toolbox.map(toolbox.evaluate, population))\n",
    "        \n",
    "        # Update the fitness values\n",
    "        for ind, fit in zip(population, fitness_values):\n",
    "            ind.fitness.values = fit\n",
    "        \n",
    "        # Select the next generation individuals\n",
    "        offspring = algorithms.varAnd(population, toolbox, cxpb=crossover_rate, mutpb=mutation_rate)\n",
    "        \n",
    "        # Evaluate offspring\n",
    "        fitness_values = list(toolbox.map(toolbox.evaluate, offspring))\n",
    "        for ind, fit in zip(offspring, fitness_values):\n",
    "            ind.fitness.values = fit\n",
    "        \n",
    "        # Select the next generation from offspring\n",
    "        population = toolbox.select(offspring + population, k=population_size)\n",
    "        \n",
    "        # Collect the highest fitness value for this generation\n",
    "        mean_fitness = np.array([ind.fitness.values[0] for ind in population]).mean()\n",
    "        mean_fitness_values.append(mean_fitness)\n",
    "\n",
    "        # Print the highest fitness value for this generation\n",
    "        print(f\"Generation {gen + 1}: Mean Fitness = {mean_fitness}\")\n",
    "\n",
    "    \n",
    "    # Plotting\n",
    "    plt.plot(range(1, generations + 1), mean_fitness_values, marker='o')\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Mean Fitness Value')\n",
    "    plt.title('Evolution of Highest Fitness Value')\n",
    "    plt.show()\n",
    "\n",
    "    # Get the best individual from the final population\n",
    "    best_individual = tools.selBest(population, k=1)[0]\n",
    "\n",
    "\n",
    "    np.savetxt(f'top_features_gen_{clf}.txt', best_individual, fmt='%s')\n",
    "\n",
    "    print(\"Best individual:\", best_individual)\n",
    "\n",
    "    return mean_fitness_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2\n",
      "1       1\n",
      "2       2\n",
      "3       2\n",
      "4       2\n",
      "       ..\n",
      "1975    2\n",
      "1976    2\n",
      "1977    2\n",
      "1978    2\n",
      "1979    2\n",
      "Name: OS_RANGE, Length: 1980, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {'short': 0, 'medium': 1, 'long': 2}\n",
    "y_numerical = y.map(label_mapping)\n",
    "\n",
    "# # Now, 'y_numerical' contains the encoded numerical values\n",
    "print(y_numerical)\n",
    "y = y_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# Function to evaluate the fitness of an individual\n",
    "def evaluate_individual_xgb(individual):\n",
    "    selected_features = individual\n",
    "    # print('selected_features: ', selected_features)\n",
    "    \n",
    "    if not selected_features:\n",
    "        return 0.0,  # Avoid all-zero individuals\n",
    "    selected_features = list(set(selected_features))\n",
    "    clf = xgb.XGBClassifier(random_state=42, n_estimators=10, n_jobs=-1)\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    \n",
    "    sel_X = X[selected_features]\n",
    "    for train_index, test_index in skf.split(sel_X, y):\n",
    "        X_train, X_test = sel_X.iloc[train_index], sel_X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    return average_accuracy,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: Mean Fitness = 0.8655050505050506\n",
      "Generation 2: Mean Fitness = 0.8668787878787879\n",
      "Generation 3: Mean Fitness = 0.8680707070707069\n",
      "Generation 4: Mean Fitness = 0.8687474747474748\n",
      "Generation 5: Mean Fitness = 0.8699595959595959\n",
      "Generation 6: Mean Fitness = 0.8708282828282828\n",
      "Generation 7: Mean Fitness = 0.8715454545454547\n",
      "Generation 8: Mean Fitness = 0.8723535353535354\n",
      "Generation 9: Mean Fitness = 0.8727070707070708\n",
      "Generation 10: Mean Fitness = 0.8727272727272728\n",
      "Generation 11: Mean Fitness = 0.8727272727272728\n",
      "Generation 12: Mean Fitness = 0.8727272727272728\n",
      "Generation 13: Mean Fitness = 0.8727272727272728\n",
      "Generation 14: Mean Fitness = 0.8727272727272728\n",
      "Generation 15: Mean Fitness = 0.8727272727272728\n",
      "Generation 16: Mean Fitness = 0.8727272727272728\n",
      "Generation 17: Mean Fitness = 0.8727272727272728\n",
      "Generation 18: Mean Fitness = 0.8727272727272728\n",
      "Generation 19: Mean Fitness = 0.8727272727272728\n"
     ]
    }
   ],
   "source": [
    "toolbox.register(\"evaluate\", evaluate_individual_xgb)\n",
    "execuate_ga('xgb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
